{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "import nltk \n",
    "import numpy\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet_ic\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('wordnet_ic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 1\n",
    "read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sport.txt\",\"r\") as file:\n",
    "    sport_text = file.read()\n",
    "    sport_list = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tech.txt\",\"r\") as file :\n",
    "    tech_text = file.read()\n",
    "    tech_list = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 2 & 3\n",
    "synsets of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "==========================================\n",
      "pharmacy\n",
      "\n",
      "_________________________________\n",
      "[synset 1]\n",
      "Synset name :   pharmacy.n.01\n",
      "Synset meaning :  the art and science of preparing and dispensing drugs and medicines,\n",
      "Synset example :  []\n",
      "Synset abstract term :   [Synset('medicine.n.01')]\n",
      "Synset tag :  n\n",
      "\n",
      "_________________________________\n",
      "[synset 2]\n",
      "Synset name :   drugstore.n.01\n",
      "Synset meaning :  a retail shop where medicine and other articles are sold\n",
      "Synset example :  []\n",
      "Synset abstract term :   [Synset('shop.n.01')]\n",
      "Synset tag :  n\n",
      "==========================================\n",
      "==========================================\n",
      "flower\n",
      "\n",
      "_________________________________\n",
      "[synset 1]\n",
      "Synset name :   flower.n.01\n",
      "Synset meaning :  a plant cultivated for its blooms or blossoms\n",
      "Synset example :  []\n",
      "Synset abstract term :   [Synset('angiosperm.n.01')]\n",
      "Synset tag :  n\n",
      "\n",
      "_________________________________\n",
      "[synset 2]\n",
      "Synset name :   flower.n.02\n",
      "Synset meaning :  reproductive organ of angiosperm plants especially one having showy or colorful parts\n",
      "Synset example :  []\n",
      "Synset abstract term :   [Synset('reproductive_structure.n.01')]\n",
      "Synset tag :  n\n",
      "\n",
      "_________________________________\n",
      "[synset 3]\n",
      "Synset name :   flower.n.03\n",
      "Synset meaning :  the period of greatest prosperity or productivity\n",
      "Synset example :  []\n",
      "Synset abstract term :   [Synset('time_period.n.01')]\n",
      "Synset tag :  n\n",
      "\n",
      "_________________________________\n",
      "[synset 4]\n",
      "Synset name :   bloom.v.01\n",
      "Synset meaning :  produce or yield flowers\n",
      "Synset example :  ['The cherry tree bloomed']\n",
      "Synset abstract term :   [Synset('develop.v.10')]\n",
      "Synset tag :  v\n",
      "==========================================\n",
      "==========================================\n",
      "dog\n",
      "\n",
      "_________________________________\n",
      "[synset 1]\n",
      "Synset name :   dog.n.01\n",
      "Synset meaning :  a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "Synset example :  ['the dog barked all night']\n",
      "Synset abstract term :   [Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
      "Synset tag :  n\n",
      "\n",
      "_________________________________\n",
      "[synset 2]\n",
      "Synset name :   frump.n.01\n",
      "Synset meaning :  a dull unattractive unpleasant girl or woman\n",
      "Synset example :  ['she got a reputation as a frump', \"she's a real dog\"]\n",
      "Synset abstract term :   [Synset('unpleasant_woman.n.01')]\n",
      "Synset tag :  n\n",
      "\n",
      "_________________________________\n",
      "[synset 3]\n",
      "Synset name :   dog.n.03\n",
      "Synset meaning :  informal term for a man\n",
      "Synset example :  ['you lucky dog']\n",
      "Synset abstract term :   [Synset('chap.n.01')]\n",
      "Synset tag :  n\n",
      "\n",
      "_________________________________\n",
      "[synset 4]\n",
      "Synset name :   cad.n.01\n",
      "Synset meaning :  someone who is morally reprehensible\n",
      "Synset example :  ['you dirty dog']\n",
      "Synset abstract term :   [Synset('villain.n.01')]\n",
      "Synset tag :  n\n",
      "\n",
      "_________________________________\n",
      "[synset 5]\n",
      "Synset name :   frank.n.02\n",
      "Synset meaning :  a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll\n",
      "Synset example :  []\n",
      "Synset abstract term :   [Synset('sausage.n.01')]\n",
      "Synset tag :  n\n",
      "\n",
      "_________________________________\n",
      "[synset 6]\n",
      "Synset name :   pawl.n.01\n",
      "Synset meaning :  a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward\n",
      "Synset example :  []\n",
      "Synset abstract term :   [Synset('catch.n.06')]\n",
      "Synset tag :  n\n",
      "\n",
      "_________________________________\n",
      "[synset 7]\n",
      "Synset name :   andiron.n.01\n",
      "Synset meaning :  metal supports for logs in a fireplace\n",
      "Synset example :  ['the andirons were too hot to touch']\n",
      "Synset abstract term :   [Synset('support.n.10')]\n",
      "Synset tag :  n\n",
      "\n",
      "_________________________________\n",
      "[synset 8]\n",
      "Synset name :   chase.v.01\n",
      "Synset meaning :  go after with the intent to catch\n",
      "Synset example :  ['The policeman chased the mugger down the alley', 'the dog chased the rabbit']\n",
      "Synset abstract term :   [Synset('pursue.v.02')]\n",
      "Synset tag :  v\n"
     ]
    }
   ],
   "source": [
    "for word in [\"pharmacy\",\"flower\",\"dog\"] :\n",
    "    print(f\"==========================================\\n==========================================\\n{word}\")\n",
    "    for index , syn in enumerate(wordnet.synsets(word)):\n",
    "        print(f\"\\n_________________________________\\n[synset {index+1}]\")\n",
    "        print (\"Synset name :  \", syn.name())\n",
    "        print (\"Synset meaning : \", syn.definition())\n",
    "        print (\"Synset example : \", syn.examples())\n",
    "        print (\"Synset abstract term :  \", syn.hypernyms())\n",
    "        print (\"Synset tag : \", syn.pos())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas(word , print_lemmas = False):\n",
    "    if print_lemmas :\n",
    "        for index , syn in enumerate(wordnet.synsets(word)):\n",
    "            print(f\"\\n_________________________________\\n[synset {index+1}] {syn.name()}\")\n",
    "            for i , lemma in enumerate(syn.lemmas()):\n",
    "                print(f\"[{i}] : \" , lemma)\n",
    "\n",
    "    return set([lemma for synset in wordnet.synsets(word) for lemma in synset.lemmas()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_________________________________\n",
      "[synset 1] banks.n.01\n",
      "[0] :  Lemma('banks.n.01.Banks')\n",
      "[1] :  Lemma('banks.n.01.Sir_Joseph_Banks')\n",
      "\n",
      "_________________________________\n",
      "[synset 2] bank.n.01\n",
      "[0] :  Lemma('bank.n.01.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 3] depository_financial_institution.n.01\n",
      "[0] :  Lemma('depository_financial_institution.n.01.depository_financial_institution')\n",
      "[1] :  Lemma('depository_financial_institution.n.01.bank')\n",
      "[2] :  Lemma('depository_financial_institution.n.01.banking_concern')\n",
      "[3] :  Lemma('depository_financial_institution.n.01.banking_company')\n",
      "\n",
      "_________________________________\n",
      "[synset 4] bank.n.03\n",
      "[0] :  Lemma('bank.n.03.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 5] bank.n.04\n",
      "[0] :  Lemma('bank.n.04.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 6] bank.n.05\n",
      "[0] :  Lemma('bank.n.05.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 7] bank.n.06\n",
      "[0] :  Lemma('bank.n.06.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 8] bank.n.07\n",
      "[0] :  Lemma('bank.n.07.bank')\n",
      "[1] :  Lemma('bank.n.07.cant')\n",
      "[2] :  Lemma('bank.n.07.camber')\n",
      "\n",
      "_________________________________\n",
      "[synset 9] savings_bank.n.02\n",
      "[0] :  Lemma('savings_bank.n.02.savings_bank')\n",
      "[1] :  Lemma('savings_bank.n.02.coin_bank')\n",
      "[2] :  Lemma('savings_bank.n.02.money_box')\n",
      "[3] :  Lemma('savings_bank.n.02.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 10] bank.n.09\n",
      "[0] :  Lemma('bank.n.09.bank')\n",
      "[1] :  Lemma('bank.n.09.bank_building')\n",
      "\n",
      "_________________________________\n",
      "[synset 11] bank.n.10\n",
      "[0] :  Lemma('bank.n.10.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 12] bank.v.01\n",
      "[0] :  Lemma('bank.v.01.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 13] bank.v.02\n",
      "[0] :  Lemma('bank.v.02.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 14] bank.v.03\n",
      "[0] :  Lemma('bank.v.03.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 15] bank.v.04\n",
      "[0] :  Lemma('bank.v.04.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 16] bank.v.05\n",
      "[0] :  Lemma('bank.v.05.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 17] deposit.v.02\n",
      "[0] :  Lemma('deposit.v.02.deposit')\n",
      "[1] :  Lemma('deposit.v.02.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 18] bank.v.07\n",
      "[0] :  Lemma('bank.v.07.bank')\n",
      "\n",
      "_________________________________\n",
      "[synset 19] trust.v.01\n",
      "[0] :  Lemma('trust.v.01.trust')\n",
      "[1] :  Lemma('trust.v.01.swear')\n",
      "[2] :  Lemma('trust.v.01.rely')\n",
      "[3] :  Lemma('trust.v.01.bank')\n"
     ]
    }
   ],
   "source": [
    "banks_lemma = get_lemmas(\"banks\",print_lemmas = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_________________________________\n",
      "[synset 1] sung.n.01\n",
      "[0] :  Lemma('sung.n.01.Sung')\n",
      "[1] :  Lemma('sung.n.01.Sung_dynasty')\n",
      "[2] :  Lemma('sung.n.01.Song')\n",
      "[3] :  Lemma('sung.n.01.Song_dynasty')\n",
      "\n",
      "_________________________________\n",
      "[synset 2] sing.v.01\n",
      "[0] :  Lemma('sing.v.01.sing')\n",
      "\n",
      "_________________________________\n",
      "[synset 3] sing.v.02\n",
      "[0] :  Lemma('sing.v.02.sing')\n",
      "\n",
      "_________________________________\n",
      "[synset 4] sing.v.03\n",
      "[0] :  Lemma('sing.v.03.sing')\n",
      "\n",
      "_________________________________\n",
      "[synset 5] whistle.v.05\n",
      "[0] :  Lemma('whistle.v.05.whistle')\n",
      "[1] :  Lemma('whistle.v.05.sing')\n",
      "\n",
      "_________________________________\n",
      "[synset 6] spill_the_beans.v.01\n",
      "[0] :  Lemma('spill_the_beans.v.01.spill_the_beans')\n",
      "[1] :  Lemma('spill_the_beans.v.01.let_the_cat_out_of_the_bag')\n",
      "[2] :  Lemma('spill_the_beans.v.01.talk')\n",
      "[3] :  Lemma('spill_the_beans.v.01.tattle')\n",
      "[4] :  Lemma('spill_the_beans.v.01.blab')\n",
      "[5] :  Lemma('spill_the_beans.v.01.peach')\n",
      "[6] :  Lemma('spill_the_beans.v.01.babble')\n",
      "[7] :  Lemma('spill_the_beans.v.01.sing')\n",
      "[8] :  Lemma('spill_the_beans.v.01.babble_out')\n",
      "[9] :  Lemma('spill_the_beans.v.01.blab_out')\n"
     ]
    }
   ],
   "source": [
    "sung_lemma = get_lemmas(\"sung\" , print_lemmas = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_opposite(word):\n",
    "    lemmas = get_lemmas(word)\n",
    "    print(f\"____________________\\nsynonyms of {word} \\n \")\n",
    "    for lemma in lemmas :\n",
    "        print(lemma.name())\n",
    "        \n",
    "    print(f\"__________________________ \\nopposite of {word}\\n\")\n",
    "    for lemma in lemmas:\n",
    "        for antonym in lemma.antonyms():\n",
    "            print(antonym.name())\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      " good\n",
      "===========================================\n",
      "____________________\n",
      "synonyms of good \n",
      " \n",
      "near\n",
      "just\n",
      "upright\n",
      "right\n",
      "secure\n",
      "salutary\n",
      "thoroughly\n",
      "undecomposed\n",
      "safe\n",
      "good\n",
      "beneficial\n",
      "skilful\n",
      "practiced\n",
      "honorable\n",
      "skillful\n",
      "soundly\n",
      "effective\n",
      "in_effect\n",
      "trade_good\n",
      "estimable\n",
      "adept\n",
      "serious\n",
      "proficient\n",
      "honest\n",
      "expert\n",
      "respectable\n",
      "unspoiled\n",
      "well\n",
      "commodity\n",
      "unspoilt\n",
      "dependable\n",
      "ripe\n",
      "goodness\n",
      "dear\n",
      "in_force\n",
      "sound\n",
      "full\n",
      "__________________________ \n",
      "opposite of good\n",
      "\n",
      "evilness\n",
      "===========================================\n",
      " better\n",
      "===========================================\n",
      "____________________\n",
      "synonyms of better \n",
      " \n",
      "near\n",
      "just\n",
      "meliorate\n",
      "upright\n",
      "right\n",
      "amend\n",
      "secure\n",
      "salutary\n",
      "undecomposed\n",
      "good\n",
      "skilful\n",
      "beneficial\n",
      "safe\n",
      "break\n",
      "practiced\n",
      "honorable\n",
      "skillful\n",
      "effective\n",
      "in_effect\n",
      "best\n",
      "estimable\n",
      "considerably\n",
      "adept\n",
      "serious\n",
      "proficient\n",
      "substantially\n",
      "intimately\n",
      "honest\n",
      "expert\n",
      "comfortably\n",
      "better\n",
      "punter\n",
      "respectable\n",
      "unspoiled\n",
      "well\n",
      "ameliorate\n",
      "unspoilt\n",
      "dependable\n",
      "bettor\n",
      "ripe\n",
      "advantageously\n",
      "dear\n",
      "wagerer\n",
      "improve\n",
      "in_force\n",
      "sound\n",
      "easily\n",
      "full\n",
      "__________________________ \n",
      "opposite of better\n",
      "\n",
      "bad\n",
      "disadvantageously\n",
      "===========================================\n",
      " dark\n",
      "===========================================\n",
      "____________________\n",
      "synonyms of dark \n",
      " \n",
      "shadow\n",
      "nighttime\n",
      "glum\n",
      "glowering\n",
      "dingy\n",
      "black\n",
      "saturnine\n",
      "dreary\n",
      "non-white\n",
      "dark-skinned\n",
      "darkness\n",
      "moody\n",
      "wickedness\n",
      "blue\n",
      "grim\n",
      "sorry\n",
      "sour\n",
      "drab\n",
      "sullen\n",
      "drear\n",
      "night\n",
      "disconsolate\n",
      "morose\n",
      "benighted\n",
      "colored\n",
      "dark\n",
      "gloomy\n",
      "iniquity\n",
      "sinister\n",
      "coloured\n",
      "dour\n",
      "dismal\n",
      "obscure\n",
      "__________________________ \n",
      "opposite of dark\n",
      "\n",
      "day\n",
      "light\n",
      "===========================================\n",
      " long\n",
      "===========================================\n",
      "____________________\n",
      "synonyms of long \n",
      " \n",
      "prospicient\n",
      "farseeing\n",
      "foresighted\n",
      "foresightful\n",
      "long\n",
      "farsighted\n",
      "recollective\n",
      "yearn\n",
      "tenacious\n",
      "longsighted\n",
      "hanker\n",
      "retentive\n",
      "__________________________ \n",
      "opposite of long\n",
      "\n",
      "unretentive\n",
      "===========================================\n",
      " car\n",
      "===========================================\n",
      "____________________\n",
      "synonyms of car \n",
      " \n",
      "motorcar\n",
      "auto\n",
      "cable_car\n",
      "railway_car\n",
      "automobile\n",
      "elevator_car\n",
      "gondola\n",
      "railroad_car\n",
      "car\n",
      "machine\n",
      "railcar\n",
      "__________________________ \n",
      "opposite of car\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in [\"good\" , \"better\" , \"dark\" , \"long\" ,\"car\"]:\n",
    "    print(f\"===========================================\\n {word}\\n===========================================\")\n",
    "    synonym_opposite(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypernyms_and_Hyponyms(word):\n",
    "    hypernyms = []\n",
    "    hyponyms=[]\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for hypernym in syn.hypernyms():\n",
    "            hypernyms.append(hypernym)\n",
    "        for hyponym in syn.hyponyms():\n",
    "            hyponyms.append(hyponym) \n",
    "            \n",
    "    return set(hypernyms),set(hyponyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "=======================\n",
      "word = car\n",
      "\n",
      "hypernyms:\n",
      "\n",
      "motor_vehicle.n.01\n",
      "compartment.n.02\n",
      "wheeled_vehicle.n.01\n",
      "______________________\n",
      "hyponyms:\n",
      "\n",
      "loaner.n.02\n",
      "horseless_carriage.n.01\n",
      "stanley_steamer.n.01\n",
      "minicar.n.01\n",
      "cruiser.n.01\n",
      "beach_wagon.n.01\n",
      "cab.n.03\n",
      "compact.n.03\n",
      "cabin_car.n.01\n",
      "sedan.n.01\n",
      "tender.n.04\n",
      "baggage_car.n.01\n",
      "ambulance.n.01\n",
      "pace_car.n.01\n",
      "hot_rod.n.01\n",
      "bus.n.04\n",
      "roadster.n.01\n",
      "model_t.n.01\n",
      "slip_coach.n.01\n",
      "hatchback.n.01\n",
      "electric.n.01\n",
      "minivan.n.01\n",
      "stock_car.n.01\n",
      "racer.n.02\n",
      "coupe.n.01\n",
      "jeep.n.01\n",
      "sports_car.n.01\n",
      "used-car.n.01\n",
      "guard's_van.n.01\n",
      "van.n.03\n",
      "touring_car.n.01\n",
      "club_car.n.01\n",
      "passenger_car.n.01\n",
      "mail_car.n.01\n",
      "gas_guzzler.n.01\n",
      "convertible.n.01\n",
      "sport_utility.n.01\n",
      "hardtop.n.01\n",
      "handcar.n.01\n",
      "freight_car.n.01\n",
      "subcompact.n.01\n",
      "limousine.n.01\n",
      "=======================\n",
      "=======================\n",
      "word = frog\n",
      "\n",
      "hypernyms:\n",
      "\n",
      "amphibian.n.03\n",
      "capture.v.06\n",
      "adornment.n.01\n",
      "frenchman.n.01\n",
      "______________________\n",
      "hyponyms:\n",
      "\n",
      "obstetrical_toad.n.01\n",
      "fire-bellied_toad.n.01\n",
      "leptodactylid_frog.n.01\n",
      "tailed_frog.n.01\n",
      "tree_toad.n.01\n",
      "true_frog.n.01\n",
      "spadefoot.n.01\n",
      "western_narrow-mouthed_toad.n.01\n",
      "robber_frog.n.02\n",
      "crapaud.n.01\n",
      "eastern_narrow-mouthed_toad.n.01\n",
      "tree_frog.n.02\n",
      "true_toad.n.01\n",
      "liopelma_hamiltoni.n.01\n",
      "south_american_poison_toad.n.01\n",
      "barking_frog.n.01\n",
      "midwife_toad.n.01\n",
      "sheep_frog.n.01\n",
      "tongueless_frog.n.01\n",
      "=======================\n",
      "=======================\n",
      "word = tree\n",
      "\n",
      "hypernyms:\n",
      "\n",
      "chase.v.01\n",
      "elongate.v.01\n",
      "steer.v.01\n",
      "plane_figure.n.01\n",
      "woody_plant.n.01\n",
      "plant.v.01\n",
      "______________________\n",
      "hyponyms:\n",
      "\n",
      "brazilian_ironwood.n.01\n",
      "tree_of_knowledge.n.01\n",
      "marmalade_tree.n.01\n",
      "birch.n.02\n",
      "sissoo.n.01\n",
      "quandong.n.01\n",
      "shade_tree.n.01\n",
      "indian_beech.n.01\n",
      "tipu.n.01\n",
      "tulipwood_tree.n.01\n",
      "ketembilla.n.01\n",
      "caracolito.n.01\n",
      "beech.n.01\n",
      "willow.n.01\n",
      "zebrawood.n.02\n",
      "tanbark_oak.n.01\n",
      "dita.n.01\n",
      "opepe.n.01\n",
      "aroeira_blanca.n.01\n",
      "quandong.n.03\n",
      "blackwood.n.02\n",
      "balata.n.02\n",
      "wild_medlar.n.01\n",
      "maria.n.02\n",
      "elm.n.01\n",
      "marblewood.n.02\n",
      "chinese_parasol_tree.n.01\n",
      "rose_chestnut.n.01\n",
      "wheel_tree.n.01\n",
      "casuarina.n.01\n",
      "hornbeam.n.01\n",
      "calaba.n.01\n",
      "treelet.n.01\n",
      "wild_fig.n.02\n",
      "anise_tree.n.01\n",
      "gymnospermous_tree.n.01\n",
      "bean_tree.n.01\n",
      "christmas_bush.n.01\n",
      "arbor.n.01\n",
      "oak_chestnut.n.01\n",
      "kingwood.n.02\n",
      "bitterwood_tree.n.01\n",
      "ice-cream_bean.n.01\n",
      "bayberry.n.01\n",
      "poon.n.02\n",
      "hazel.n.01\n",
      "calabash.n.02\n",
      "kowhai.n.01\n",
      "inga.n.01\n",
      "cork_tree.n.01\n",
      "aalii.n.01\n",
      "timber_tree.n.01\n",
      "southern_beech.n.01\n",
      "clusia.n.01\n",
      "fringe_tree.n.01\n",
      "angelim.n.01\n",
      "ivory_tree.n.01\n",
      "millettia.n.01\n",
      "jamaican_cherry.n.01\n",
      "camwood.n.01\n",
      "plane_tree.n.01\n",
      "satinwood.n.03\n",
      "wild_tamarind.n.02\n",
      "gutta-percha_tree.n.01\n",
      "necklace_tree.n.01\n",
      "sandalwood_tree.n.01\n",
      "pandanus.n.02\n",
      "silver_tree.n.01\n",
      "lemonwood.n.02\n",
      "cladogram.n.01\n",
      "obeche.n.02\n",
      "chinaberry.n.02\n",
      "gum_tree.n.01\n",
      "acacia.n.01\n",
      "gutta-percha_tree.n.02\n",
      "pollard.n.01\n",
      "mescal_bean.n.01\n",
      "shaving-brush_tree.n.01\n",
      "prickly_ash.n.02\n",
      "albizzia.n.01\n",
      "keurboom.n.01\n",
      "neem.n.01\n",
      "princewood.n.01\n",
      "idesia.n.01\n",
      "snag.n.02\n",
      "angiospermous_tree.n.01\n",
      "palo_verde.n.01\n",
      "australian_nettle.n.01\n",
      "bonduc.n.02\n",
      "bonsai.n.01\n",
      "dhak.n.01\n",
      "linden.n.02\n",
      "red_silk-cotton_tree.n.01\n",
      "teak.n.02\n",
      "white_mangrove.n.02\n",
      "lacebark.n.01\n",
      "palm.n.03\n",
      "giant_chinkapin.n.01\n",
      "white_mangrove.n.01\n",
      "tolu_tree.n.01\n",
      "mayeng.n.01\n",
      "rosewood.n.02\n",
      "pepper_tree.n.02\n",
      "lead_tree.n.01\n",
      "lepidobotrys.n.01\n",
      "guinea_pepper.n.02\n",
      "kentucky_coffee_tree.n.01\n",
      "cinchona.n.02\n",
      "conacaste.n.01\n",
      "gliricidia.n.01\n",
      "puka.n.02\n",
      "ribbon_tree.n.01\n",
      "granadilla_tree.n.01\n",
      "laurelwood.n.01\n",
      "jamaica_dogwood.n.01\n",
      "cabbage_tree.n.03\n",
      "trifoliate_orange.n.01\n",
      "coral_tree.n.01\n",
      "yellowwood.n.02\n",
      "turreae.n.01\n",
      "souari.n.01\n",
      "chaulmoogra.n.01\n",
      "cockspur.n.02\n",
      "red_sandalwood.n.02\n",
      "dhawa.n.01\n",
      "shingle_tree.n.01\n",
      "brazilwood.n.02\n",
      "hop_hornbeam.n.01\n",
      "winter's_bark.n.02\n",
      "fever_tree.n.01\n",
      "hackberry.n.01\n",
      "keurboom.n.02\n",
      "dagame.n.01\n",
      "burma_padauk.n.01\n",
      "silver_ash.n.01\n",
      "manila_tamarind.n.01\n",
      "nakedwood.n.01\n",
      "african_walnut.n.01\n",
      "quira.n.02\n",
      "montezuma.n.01\n",
      "spanish_tamarind.n.01\n",
      "breakax.n.01\n",
      "pepper_tree.n.01\n",
      "coffee.n.02\n",
      "chestnut.n.02\n",
      "peruvian_balsam.n.01\n",
      "devilwood.n.01\n",
      "sapling.n.01\n",
      "brazilian_pepper_tree.n.01\n",
      "kino.n.02\n",
      "prickly_ash.n.01\n",
      "japanese_pagoda_tree.n.01\n",
      "nitta_tree.n.01\n",
      "hydnocarpus_laurifolia.n.01\n",
      "guama.n.01\n",
      "mahogany.n.02\n",
      "divi-divi.n.02\n",
      "fig_tree.n.01\n",
      "locust_tree.n.01\n",
      "oak.n.02\n",
      "stemma.n.01\n",
      "scarlet_wisteria_tree.n.01\n",
      "coralwood.n.01\n",
      "black_mangrove.n.01\n",
      "dipterocarp.n.01\n",
      "incense_tree.n.01\n",
      "lancewood.n.02\n",
      "alder.n.02\n",
      "button_tree.n.01\n",
      "msasa.n.01\n",
      "soapberry.n.01\n",
      "ash.n.02\n",
      "padauk.n.01\n",
      "cocobolo.n.01\n",
      "ebony.n.03\n",
      "cassia.n.01\n",
      "scrub_beefwood.n.01\n",
      "bloodwood_tree.n.01\n",
      "bottle-tree.n.01\n",
      "carib_wood.n.01\n",
      "silver_tree.n.02\n",
      "lanseh_tree.n.01\n"
     ]
    }
   ],
   "source": [
    "for word in [\"car\",\"frog\",\"tree\"]:\n",
    "    print(f\"=======================\\n=======================\\nword = {word}\\n\\nhypernyms:\\n\")\n",
    "    hypernyms,hyponyms = get_hypernyms_and_Hyponyms(word)\n",
    "    for hypernym in hypernyms:\n",
    "        print(hypernym.name())\n",
    "    print(\"______________________\\nhyponyms:\\n\")\n",
    "    for hyponym in hyponyms:\n",
    "        print(hyponym.name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 7 \n",
    "## part 7-a\n",
    "root hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet.synset(word).root_hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word = Dog     => ['entity.n.01']\n",
      "word = Cat     => ['entity.n.01']\n",
      "word = Car     => ['entity.n.01']\n",
      "word = Bicycle => ['entity.n.01']\n",
      "word = Tree    => ['entity.n.01']\n",
      "word = Flower  => ['entity.n.01']\n",
      "word = Water   => ['entity.n.01']\n",
      "word = Rainbow => ['entity.n.01']\n"
     ]
    }
   ],
   "source": [
    "for word in [\"Dog\",\"Cat\",\"Car\",\"Bicycle\",\"Tree\",\"Flower\",\"Water\",\"Rainbow\"]:\n",
    "    root_hypernyms = wordnet.synsets(word)[0].root_hypernyms()\n",
    "    print(f\"word = {word}\".ljust(15) +f\"=> {[item.name() for item in root_hypernyms]}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 7-b\n",
    "Lowest common hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Dog & Cat       => ['carnivore.n.01']\n",
      "for Car & Bicycle   => ['wheeled_vehicle.n.01']\n",
      "for Tree & Flower   => ['vascular_plant.n.01']\n",
      "for Water & Rainbow => ['abstraction.n.06']\n"
     ]
    }
   ],
   "source": [
    "for word1,word2 in [(\"Dog\",\"Cat\"),(\"Car\",\"Bicycle\"),(\"Tree\" ,\"Flower\"),(\"Water\",\"Rainbow\")]:\n",
    "    syn1 = wordnet.synsets(word1)[0]\n",
    "    syn2 = wordnet.synsets(word2)[0]\n",
    "    lowest_common_hypernyms = syn1.lowest_common_hypernyms(syn2)\n",
    "    print(f\"for {word1} & {word2}\".ljust(20) +f\"=> {[item.name() for item in lowest_common_hypernyms]}\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"Dog\",\"Cat\",\"Car\",\"Bicycle\",\"Tree\",\"Flower\",\"Water\",\"Rainbow\"]\n",
    "path_similarities = numpy.zeros((8,8))\n",
    "resnik_similarities = numpy.zeros((8,8))\n",
    "jiang_conrath_similarities = numpy.zeros((8,8))\n",
    "\n",
    "for index1 , word1 in enumerate(words):\n",
    "    for index2 , word2 in enumerate(words):\n",
    "        syn1 = wordnet.synsets(word1)[0]\n",
    "        syn2 = wordnet.synsets(word2)[0]\n",
    "        \n",
    "        # path similarity\n",
    "        path_similarities[index1,index2]=syn1.path_similarity(syn2)\n",
    "        \n",
    "        # resnik_similarity \n",
    "        resnik_similarities[index1,index2] = syn1.res_similarity(syn2,wordnet_ic.ic(\"ic-brown.dat\"))\n",
    "        \n",
    "        #jiang_conrath_similarity\n",
    "        jiang_conrath_similarities[index1,index2]=syn1.jcn_similarity(syn2,wordnet_ic.ic(\"ic-brown.dat\"))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### path_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Car</th>\n",
       "      <th>Bicycle</th>\n",
       "      <th>Tree</th>\n",
       "      <th>Flower</th>\n",
       "      <th>Water</th>\n",
       "      <th>Rainbow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dog</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bicycle</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tree</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flower</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rainbow</th>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dog       Cat       Car   Bicycle      Tree    Flower     Water  \\\n",
       "Dog      1.000000  0.200000  0.076923  0.090909  0.125000  0.111111  0.083333   \n",
       "Cat      0.200000  1.000000  0.055556  0.062500  0.076923  0.071429  0.058824   \n",
       "Car      0.076923  0.055556  1.000000  0.200000  0.071429  0.066667  0.071429   \n",
       "Bicycle  0.090909  0.062500  0.200000  1.000000  0.083333  0.076923  0.083333   \n",
       "Tree     0.125000  0.076923  0.071429  0.083333  1.000000  0.166667  0.076923   \n",
       "Flower   0.111111  0.071429  0.066667  0.076923  0.166667  1.000000  0.071429   \n",
       "Water    0.083333  0.058824  0.071429  0.083333  0.076923  0.071429  1.000000   \n",
       "Rainbow  0.062500  0.047619  0.055556  0.062500  0.058824  0.055556  0.076923   \n",
       "\n",
       "          Rainbow  \n",
       "Dog      0.062500  \n",
       "Cat      0.047619  \n",
       "Car      0.055556  \n",
       "Bicycle  0.062500  \n",
       "Tree     0.058824  \n",
       "Flower   0.055556  \n",
       "Water    0.076923  \n",
       "Rainbow  1.000000  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(path_similarities , columns=words , index=words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnik_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Car</th>\n",
       "      <th>Bicycle</th>\n",
       "      <th>Tree</th>\n",
       "      <th>Flower</th>\n",
       "      <th>Water</th>\n",
       "      <th>Rainbow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dog</th>\n",
       "      <td>9.006014</td>\n",
       "      <td>7.911667</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>2.224150</td>\n",
       "      <td>2.224150</td>\n",
       "      <td>0.801759</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <td>7.911667</td>\n",
       "      <td>9.040650</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>2.224150</td>\n",
       "      <td>2.224150</td>\n",
       "      <td>0.801759</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car</th>\n",
       "      <td>1.531834</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>7.591401</td>\n",
       "      <td>6.452257</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>0.801759</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bicycle</th>\n",
       "      <td>1.531834</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>6.452257</td>\n",
       "      <td>9.250664</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>0.801759</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tree</th>\n",
       "      <td>2.224150</td>\n",
       "      <td>2.224150</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>7.764869</td>\n",
       "      <td>6.028316</td>\n",
       "      <td>0.801759</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flower</th>\n",
       "      <td>2.224150</td>\n",
       "      <td>2.224150</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>1.531834</td>\n",
       "      <td>6.028316</td>\n",
       "      <td>8.295989</td>\n",
       "      <td>0.801759</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water</th>\n",
       "      <td>0.801759</td>\n",
       "      <td>0.801759</td>\n",
       "      <td>0.801759</td>\n",
       "      <td>0.801759</td>\n",
       "      <td>0.801759</td>\n",
       "      <td>0.801759</td>\n",
       "      <td>8.206018</td>\n",
       "      <td>0.596229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rainbow</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.596229</td>\n",
       "      <td>12.856162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dog       Cat       Car   Bicycle      Tree    Flower     Water  \\\n",
       "Dog      9.006014  7.911667  1.531834  1.531834  2.224150  2.224150  0.801759   \n",
       "Cat      7.911667  9.040650  1.531834  1.531834  2.224150  2.224150  0.801759   \n",
       "Car      1.531834  1.531834  7.591401  6.452257  1.531834  1.531834  0.801759   \n",
       "Bicycle  1.531834  1.531834  6.452257  9.250664  1.531834  1.531834  0.801759   \n",
       "Tree     2.224150  2.224150  1.531834  1.531834  7.764869  6.028316  0.801759   \n",
       "Flower   2.224150  2.224150  1.531834  1.531834  6.028316  8.295989  0.801759   \n",
       "Water    0.801759  0.801759  0.801759  0.801759  0.801759  0.801759  8.206018   \n",
       "Rainbow -0.000000 -0.000000 -0.000000 -0.000000 -0.000000 -0.000000  0.596229   \n",
       "\n",
       "           Rainbow  \n",
       "Dog      -0.000000  \n",
       "Cat      -0.000000  \n",
       "Car      -0.000000  \n",
       "Bicycle  -0.000000  \n",
       "Tree     -0.000000  \n",
       "Flower   -0.000000  \n",
       "Water     0.596229  \n",
       "Rainbow  12.856162  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(resnik_similarities , columns=words , index=words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jiang_conrath_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Car</th>\n",
       "      <th>Bicycle</th>\n",
       "      <th>Tree</th>\n",
       "      <th>Flower</th>\n",
       "      <th>Water</th>\n",
       "      <th>Rainbow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dog</th>\n",
       "      <td>inf</td>\n",
       "      <td>0.449776</td>\n",
       "      <td>0.073889</td>\n",
       "      <td>0.065820</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>0.077799</td>\n",
       "      <td>0.064068</td>\n",
       "      <td>0.045741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <td>0.449776</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.073701</td>\n",
       "      <td>0.065670</td>\n",
       "      <td>0.080924</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.063926</td>\n",
       "      <td>0.045669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car</th>\n",
       "      <td>0.073889</td>\n",
       "      <td>0.073701</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.253965</td>\n",
       "      <td>0.081350</td>\n",
       "      <td>0.077980</td>\n",
       "      <td>0.070453</td>\n",
       "      <td>0.048906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bicycle</th>\n",
       "      <td>0.065820</td>\n",
       "      <td>0.065670</td>\n",
       "      <td>0.253965</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.071675</td>\n",
       "      <td>0.069047</td>\n",
       "      <td>0.063079</td>\n",
       "      <td>0.045235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tree</th>\n",
       "      <td>0.081152</td>\n",
       "      <td>0.080924</td>\n",
       "      <td>0.081350</td>\n",
       "      <td>0.071675</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.249736</td>\n",
       "      <td>0.069602</td>\n",
       "      <td>0.048494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flower</th>\n",
       "      <td>0.077799</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.077980</td>\n",
       "      <td>0.069047</td>\n",
       "      <td>0.249736</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.067121</td>\n",
       "      <td>0.047277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water</th>\n",
       "      <td>0.064068</td>\n",
       "      <td>0.063926</td>\n",
       "      <td>0.070453</td>\n",
       "      <td>0.063079</td>\n",
       "      <td>0.069602</td>\n",
       "      <td>0.067121</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.050328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rainbow</th>\n",
       "      <td>0.045741</td>\n",
       "      <td>0.045669</td>\n",
       "      <td>0.048906</td>\n",
       "      <td>0.045235</td>\n",
       "      <td>0.048494</td>\n",
       "      <td>0.047277</td>\n",
       "      <td>0.050328</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dog       Cat       Car   Bicycle      Tree    Flower     Water  \\\n",
       "Dog           inf  0.449776  0.073889  0.065820  0.081152  0.077799  0.064068   \n",
       "Cat      0.449776       inf  0.073701  0.065670  0.080924  0.077590  0.063926   \n",
       "Car      0.073889  0.073701       inf  0.253965  0.081350  0.077980  0.070453   \n",
       "Bicycle  0.065820  0.065670  0.253965       inf  0.071675  0.069047  0.063079   \n",
       "Tree     0.081152  0.080924  0.081350  0.071675       inf  0.249736  0.069602   \n",
       "Flower   0.077799  0.077590  0.077980  0.069047  0.249736       inf  0.067121   \n",
       "Water    0.064068  0.063926  0.070453  0.063079  0.069602  0.067121       inf   \n",
       "Rainbow  0.045741  0.045669  0.048906  0.045235  0.048494  0.047277  0.050328   \n",
       "\n",
       "          Rainbow  \n",
       "Dog      0.045741  \n",
       "Cat      0.045669  \n",
       "Car      0.048906  \n",
       "Bicycle  0.045235  \n",
       "Tree     0.048494  \n",
       "Flower   0.047277  \n",
       "Water    0.050328  \n",
       "Rainbow       inf  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(jiang_conrath_similarities , columns=words , index=words  )\n",
    "df.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 9\n",
    "## part 9-a :\n",
    "tokenize and delete stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_tokens = regexp_tokenize(sport_text,\"\\w+\")\n",
    "tech_tokens = regexp_tokenize(tech_text,\"\\w+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 9-b :\n",
    "delete stopwords and single character words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_tokens = [word for word in sport_tokens if len(word)>1 and word.lower() not in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_tokens = [word for word in tech_tokens if len(word)>1 and word.lower() not in stopwords.words(\"english\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 9-c:\n",
    "types of texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for sports :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "types count :  11010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Hamm',\n",
       " 'stage',\n",
       " 'treated',\n",
       " 'definitive',\n",
       " 'foster',\n",
       " 'Luscombe',\n",
       " 'middle',\n",
       " 'survive',\n",
       " 'repair',\n",
       " 'Midlands',\n",
       " 'Hillsborough',\n",
       " 'maintain',\n",
       " 'Joice',\n",
       " '10',\n",
       " 'Mexicans',\n",
       " 'Harper',\n",
       " 'honeymoon',\n",
       " 'Negras',\n",
       " 'executed',\n",
       " 'KP',\n",
       " 'rage',\n",
       " 'refers',\n",
       " 'lifts',\n",
       " 'aspects',\n",
       " 'liquid',\n",
       " 'golds',\n",
       " 'gloom',\n",
       " 'closely',\n",
       " 'Na',\n",
       " 'Partridge',\n",
       " 'Bernard',\n",
       " 'Earnshaw',\n",
       " 'offered',\n",
       " 'meticulous',\n",
       " 'excuse',\n",
       " 'relentless',\n",
       " 'packs',\n",
       " 'ferocious',\n",
       " 'condition',\n",
       " 'Referees',\n",
       " 'period',\n",
       " 'evidence',\n",
       " 'fashioned',\n",
       " 'swelling',\n",
       " 'Hewitt',\n",
       " 'Canio',\n",
       " 'Borthwick',\n",
       " 'enjoys',\n",
       " 'contra',\n",
       " 'crossbar',\n",
       " 'Alistair',\n",
       " 'coup',\n",
       " 'judgement',\n",
       " 'colours',\n",
       " 'Night',\n",
       " '12th',\n",
       " 'referred',\n",
       " 'planks',\n",
       " 'commissioner',\n",
       " 'Dallaglio',\n",
       " 'credit',\n",
       " 'territory',\n",
       " 'LDV',\n",
       " 'Canada',\n",
       " 'talisman',\n",
       " 'question',\n",
       " 'Budapest',\n",
       " 'Melville',\n",
       " 'Hellenic',\n",
       " 'Almeria',\n",
       " 'turnovers',\n",
       " 'stormed',\n",
       " 'reasonably',\n",
       " 'Harel',\n",
       " 'spite',\n",
       " 'Zimbabwe',\n",
       " '1430',\n",
       " 'Subs',\n",
       " 'prejudge',\n",
       " 'trailing',\n",
       " '163',\n",
       " 'flat',\n",
       " 'view',\n",
       " 'Everton',\n",
       " 'debuts',\n",
       " 'Faregas',\n",
       " 'scragged',\n",
       " 'Letter',\n",
       " 'Bryan',\n",
       " 'Alessandro',\n",
       " 'supported',\n",
       " 'animosity',\n",
       " 'using',\n",
       " 'Bringing',\n",
       " 'reduced',\n",
       " 'Anticipation',\n",
       " 'Scanlon',\n",
       " 'Bryson',\n",
       " 'order',\n",
       " 'store',\n",
       " 'High',\n",
       " 'Baxter',\n",
       " 'undeniable',\n",
       " 'Early',\n",
       " 'Basque',\n",
       " 'businessman',\n",
       " 'mistakenly',\n",
       " 'evasion',\n",
       " 'punish',\n",
       " 'millions',\n",
       " 'Childs',\n",
       " 'Joaquin',\n",
       " 'Peruvian',\n",
       " 'McCormick',\n",
       " 'tourists',\n",
       " 'Disappointed',\n",
       " 'thrashed',\n",
       " 'strolled',\n",
       " 'slow',\n",
       " 'prosper',\n",
       " 'ligament',\n",
       " 'Sveta',\n",
       " 'entering',\n",
       " 'Reebok',\n",
       " 'Rio',\n",
       " 'dealt',\n",
       " 'Blacks',\n",
       " 'captains',\n",
       " 'Casey',\n",
       " 'revamped',\n",
       " 'enthralling',\n",
       " 'declining',\n",
       " 'Ideally',\n",
       " 'viewing',\n",
       " '2km',\n",
       " 'deterioration',\n",
       " 'clinches',\n",
       " 'Geneti',\n",
       " 'Aurelien',\n",
       " 'alarms',\n",
       " 'perpetrators',\n",
       " 'net',\n",
       " 'mantle',\n",
       " 'report',\n",
       " 'leaving',\n",
       " 'speak',\n",
       " 'Elliott',\n",
       " 'rescue',\n",
       " 'Tosin',\n",
       " 'Nadal',\n",
       " 'botched',\n",
       " 'Queudrue',\n",
       " 'Surrey',\n",
       " 'picked',\n",
       " 'urine',\n",
       " 'Dinamo',\n",
       " 'perspective',\n",
       " 'Stradey',\n",
       " 'heated',\n",
       " 'pacemaker',\n",
       " 'deserve',\n",
       " 'Rings',\n",
       " 'reluctant',\n",
       " 'levels',\n",
       " 'Ioanidis',\n",
       " 'path',\n",
       " 'left',\n",
       " 'Uzzell',\n",
       " 'rankings',\n",
       " 'Leipzig',\n",
       " 'FC',\n",
       " 'impetus',\n",
       " 'Number',\n",
       " 'stem',\n",
       " 'stock',\n",
       " 'windy',\n",
       " 'Rabeni',\n",
       " 'Boldon',\n",
       " 'business',\n",
       " 'reponse',\n",
       " 'Perez',\n",
       " 'set',\n",
       " 'Valente',\n",
       " 'missile',\n",
       " 'range',\n",
       " 'Jonatan',\n",
       " 'Kaka',\n",
       " 'Slam',\n",
       " 'rates',\n",
       " 'grips',\n",
       " 'standpoint',\n",
       " 'pulls',\n",
       " 'void',\n",
       " 'Midfielder',\n",
       " '13th',\n",
       " 'wrong',\n",
       " 'showing',\n",
       " 'Brive',\n",
       " 'magician',\n",
       " 'refuses',\n",
       " 'clouded',\n",
       " 'WTA',\n",
       " 'longest',\n",
       " 'creates',\n",
       " 'tempted',\n",
       " 'qualify',\n",
       " 'Dunwoody',\n",
       " 'nitrogen',\n",
       " 'singles',\n",
       " 'intended',\n",
       " 'McEnroe',\n",
       " 'tendon',\n",
       " 'Back',\n",
       " 'caretaker',\n",
       " 'Tourists',\n",
       " 'adds',\n",
       " 'least',\n",
       " 'shut',\n",
       " 'tough',\n",
       " 'forging',\n",
       " 'Park',\n",
       " 'school',\n",
       " 'colloquial',\n",
       " 'Warnock',\n",
       " 'Stuart',\n",
       " 'distribution',\n",
       " 'Faulkner',\n",
       " 'Gillies',\n",
       " 'ethic',\n",
       " 'individually',\n",
       " 'Depor',\n",
       " 'en',\n",
       " 'Duffer',\n",
       " 'dying',\n",
       " 'impress',\n",
       " 'USTA',\n",
       " 'daily',\n",
       " 'native',\n",
       " 'haematoma',\n",
       " 'Vignal',\n",
       " 'whereabouts',\n",
       " '82',\n",
       " 'Dublin',\n",
       " 'medals',\n",
       " 'Francesca',\n",
       " 'vastly',\n",
       " 'postponed',\n",
       " 'door',\n",
       " 'Saulnier',\n",
       " 'fielded',\n",
       " 'Borders',\n",
       " 'partner',\n",
       " 'reassurance',\n",
       " 'Janine',\n",
       " 'motorcycle',\n",
       " 'Rankin',\n",
       " 'metatarsal',\n",
       " 'Benita',\n",
       " 'job',\n",
       " 'Earlier',\n",
       " 'hots',\n",
       " 'struggles',\n",
       " 'Linvoy',\n",
       " 'cutting',\n",
       " 'brimming',\n",
       " 'legs',\n",
       " 'wake',\n",
       " 'PSG',\n",
       " 'Balshaw',\n",
       " 'country',\n",
       " 'redemption',\n",
       " 'circulate',\n",
       " 'streamed',\n",
       " 'Sweeney',\n",
       " 'Batie',\n",
       " 'Fernando',\n",
       " 'tricky',\n",
       " 'March',\n",
       " 'Jose',\n",
       " 'wondering',\n",
       " 'answered',\n",
       " 'pleasing',\n",
       " 'agenda',\n",
       " 'loses',\n",
       " 'Magne',\n",
       " 'Serge',\n",
       " 'prominently',\n",
       " 'alongside',\n",
       " 'Gaudio',\n",
       " 'Athletico',\n",
       " 'Austin',\n",
       " 'Stefano',\n",
       " 'sanctioned',\n",
       " 'Wednesday',\n",
       " 'tinkers',\n",
       " 'jerseys',\n",
       " 'Rotterdam',\n",
       " 'sanction',\n",
       " 'convenient',\n",
       " 'possibilities',\n",
       " 'Sally',\n",
       " 'pacy',\n",
       " 'Petrova',\n",
       " 'Zabaleta',\n",
       " 'many',\n",
       " 'minimise',\n",
       " 'bruising',\n",
       " 'fatigued',\n",
       " 'Rab',\n",
       " 'relax',\n",
       " 'outfit',\n",
       " 'amateurish',\n",
       " 'crisp',\n",
       " 'withstood',\n",
       " 'surrendered',\n",
       " 'fabulous',\n",
       " 'warns',\n",
       " 'wrestling',\n",
       " 'massive',\n",
       " 'elected',\n",
       " 'Keeper',\n",
       " 'Jackson',\n",
       " 'Ingham',\n",
       " 'volvi',\n",
       " 'Goldstein',\n",
       " 'Ken',\n",
       " 'upsets',\n",
       " 'operate',\n",
       " 'Clemence',\n",
       " 'Rupert',\n",
       " 'Davydenko',\n",
       " 'catch',\n",
       " 'particular',\n",
       " 'obsession',\n",
       " 'RFU',\n",
       " 'shaved',\n",
       " 'Srebotnik',\n",
       " 'Squad',\n",
       " 'inside',\n",
       " 'exerted',\n",
       " 'wrist',\n",
       " 'penalised',\n",
       " 'products',\n",
       " 'ruing',\n",
       " 'Kiefer',\n",
       " 'Carr',\n",
       " 'highs',\n",
       " 'yes',\n",
       " 'listed',\n",
       " 'minute',\n",
       " 'offer',\n",
       " 'thrown',\n",
       " 'evident',\n",
       " 'Schofield',\n",
       " 'dour',\n",
       " 'expertise',\n",
       " 'dominance',\n",
       " '22nd',\n",
       " 'brush',\n",
       " 'value',\n",
       " 'joked',\n",
       " 'Ghanaian',\n",
       " 'tamely',\n",
       " 'Villar',\n",
       " 'thoroughly',\n",
       " 'mount',\n",
       " 'fulfil',\n",
       " 'nice',\n",
       " 'fitness',\n",
       " 'draws',\n",
       " 'relayed',\n",
       " 'tunnel',\n",
       " 'Desailly',\n",
       " 'Operative',\n",
       " 'mercurial',\n",
       " 'Peter',\n",
       " 'soared',\n",
       " 'unpaid',\n",
       " 'penned',\n",
       " 'investigations',\n",
       " 'Citizen',\n",
       " 'Marcel',\n",
       " 'normal',\n",
       " 'together',\n",
       " 'drinks',\n",
       " 'Henin',\n",
       " 'Soon',\n",
       " 'Gross',\n",
       " 'impressed',\n",
       " 'Allen',\n",
       " 'barriers',\n",
       " 'Brilliant',\n",
       " 'Bernie',\n",
       " 'Hitzlsperger',\n",
       " 'planning',\n",
       " 'interest',\n",
       " 'handicap',\n",
       " 'Arena',\n",
       " 'jackass',\n",
       " 'guess',\n",
       " 'Levy',\n",
       " 'caught',\n",
       " 'vulnerable',\n",
       " '500',\n",
       " 'smallest',\n",
       " 'solidifies',\n",
       " 'row',\n",
       " 'State',\n",
       " 'Edmondson',\n",
       " '04',\n",
       " '36th',\n",
       " 'Jamaican',\n",
       " 'lived',\n",
       " 'Tunisia',\n",
       " 'deft',\n",
       " 'pattern',\n",
       " 'silver',\n",
       " 'Knowsley',\n",
       " 'landscape',\n",
       " 'relatively',\n",
       " 'emerging',\n",
       " 'bomb',\n",
       " 'pronouncement',\n",
       " 'surfaced',\n",
       " 'drive',\n",
       " 'party',\n",
       " 'intelligent',\n",
       " 'Dubai',\n",
       " 'shaped',\n",
       " 'balanced',\n",
       " 'summit',\n",
       " 'storming',\n",
       " 'bows',\n",
       " 'extra',\n",
       " 'Lamine',\n",
       " 'ensure',\n",
       " 'tracking',\n",
       " 'stomach',\n",
       " 'potency',\n",
       " 'mistiming',\n",
       " 'snatched',\n",
       " 'intimidating',\n",
       " 'organised',\n",
       " 'twins',\n",
       " 'drag',\n",
       " 'Aizlewood',\n",
       " 'dea',\n",
       " 'Cagigal',\n",
       " 'Maling',\n",
       " '22',\n",
       " 'Karen',\n",
       " 'Claassens',\n",
       " 'Clijsters',\n",
       " 'Sawyer',\n",
       " 'Yeading',\n",
       " 'Stokes',\n",
       " 'Coventry',\n",
       " 'Casillas',\n",
       " 'ousted',\n",
       " 'Jerry',\n",
       " 'Louise',\n",
       " 'waging',\n",
       " 'uphill',\n",
       " 'wished',\n",
       " 'something',\n",
       " 'Hyuung',\n",
       " 'stopped',\n",
       " 'supporting',\n",
       " 'Narraway',\n",
       " 'undecided',\n",
       " 'Coast',\n",
       " 'Xabi',\n",
       " 'Hoddle',\n",
       " 'drawn',\n",
       " 'knee',\n",
       " 'Jake',\n",
       " 'hope',\n",
       " 'share',\n",
       " 'Djhone',\n",
       " 'Herron',\n",
       " 'LW',\n",
       " 'McLaughlin',\n",
       " 'stand',\n",
       " 'groups',\n",
       " 'Sodje',\n",
       " 'barren',\n",
       " 'likelier',\n",
       " 'inspired',\n",
       " 'Stephenson',\n",
       " 'Bramble',\n",
       " 'Harris',\n",
       " 'seal',\n",
       " 'delivered',\n",
       " 'airport',\n",
       " 'pounced',\n",
       " 'surreal',\n",
       " 'allows',\n",
       " 'consult',\n",
       " '66m',\n",
       " 'absurd',\n",
       " 'Horgan',\n",
       " 'Orquera',\n",
       " 'spilled',\n",
       " 'produced',\n",
       " 'Bahoken',\n",
       " 'ankle',\n",
       " 'aspect',\n",
       " 'Gaston',\n",
       " 'ecstatic',\n",
       " 'Eyton',\n",
       " 'peformance',\n",
       " 'initiatives',\n",
       " 'strugglers',\n",
       " 'injunction',\n",
       " 'assumption',\n",
       " 'Grayson',\n",
       " 'minor',\n",
       " 'Village',\n",
       " 'stance',\n",
       " 'crunch',\n",
       " 'announcing',\n",
       " 'Kel',\n",
       " 'Scotland',\n",
       " 'survived',\n",
       " 'enabled',\n",
       " 'backing',\n",
       " 'whingeing',\n",
       " 'athletes',\n",
       " 'Olympiakos',\n",
       " 'Artell',\n",
       " 'booked',\n",
       " 'subsequent',\n",
       " 'official',\n",
       " 'solve',\n",
       " 'early',\n",
       " 'forgetting',\n",
       " 'advise',\n",
       " 'Rory',\n",
       " 'fetches',\n",
       " '69',\n",
       " 'Todd',\n",
       " '35m',\n",
       " 'disrupt',\n",
       " '36',\n",
       " 'Kingsholm',\n",
       " 'complaints',\n",
       " 'satisfy',\n",
       " 'festive',\n",
       " 'illness',\n",
       " 'particularly',\n",
       " 'follow',\n",
       " 'Griffiths',\n",
       " 'barrier',\n",
       " 'Banks',\n",
       " 'Zara',\n",
       " 'Radio',\n",
       " 'selfish',\n",
       " 'related',\n",
       " 'assessment',\n",
       " 'Referee',\n",
       " 'semi',\n",
       " 'backhands',\n",
       " 'viewpoint',\n",
       " 'loose',\n",
       " 'performance',\n",
       " '23secs',\n",
       " 'vowed',\n",
       " 'blossoming',\n",
       " 'Lomana',\n",
       " 'progress',\n",
       " 'overweight',\n",
       " 'crying',\n",
       " 'Ground',\n",
       " 'ruffled',\n",
       " 'GMR',\n",
       " 'combination',\n",
       " '90',\n",
       " 'tsumani',\n",
       " 'relationship',\n",
       " 'ejection',\n",
       " 'hype',\n",
       " 'rid',\n",
       " 'psychological',\n",
       " 'Anastasia',\n",
       " 'Pete',\n",
       " 'Slovenia',\n",
       " 'quite',\n",
       " 'omission',\n",
       " 'complicated',\n",
       " 'Honours',\n",
       " 'pressure',\n",
       " 'crowning',\n",
       " 'charity',\n",
       " 'ruling',\n",
       " 'century',\n",
       " 'fallen',\n",
       " 'titanium',\n",
       " 'Edinburgh',\n",
       " 'Personally',\n",
       " 'ago',\n",
       " 'amid',\n",
       " 'Norway',\n",
       " 'Arcy',\n",
       " 'rights',\n",
       " 'Less',\n",
       " 'joins',\n",
       " 'riot',\n",
       " 'damn',\n",
       " 'faking',\n",
       " 'weaker',\n",
       " 'Wallaby',\n",
       " 'purely',\n",
       " 'drifting',\n",
       " 'extent',\n",
       " 'Dudek',\n",
       " 'Horsman',\n",
       " 'cum',\n",
       " 'Hamish',\n",
       " 'se',\n",
       " 'Wolverhampton',\n",
       " 'footage',\n",
       " 'Irina',\n",
       " 'Kallur',\n",
       " 'ashamed',\n",
       " 'makeshift',\n",
       " 'China',\n",
       " 'Africa',\n",
       " 'Blackburn',\n",
       " 'Thursday',\n",
       " 'Barbini',\n",
       " 'Crawley',\n",
       " 'brothers',\n",
       " 'ephedrine',\n",
       " 'eclipses',\n",
       " 'superior',\n",
       " 'Padova',\n",
       " 'proviso',\n",
       " 'Alexis',\n",
       " 'employees',\n",
       " 'inability',\n",
       " 'tag',\n",
       " 'vault',\n",
       " 'prosecution',\n",
       " 'finger',\n",
       " 'Nomar',\n",
       " 'ensuring',\n",
       " 'Bogdanov',\n",
       " 'consolation',\n",
       " 'summer',\n",
       " 'equalled',\n",
       " 'concerns',\n",
       " 'darling',\n",
       " 'fan',\n",
       " 'Barker',\n",
       " 'snap',\n",
       " 'None',\n",
       " 'WADA',\n",
       " 'taught',\n",
       " 'striker',\n",
       " 'Dominic',\n",
       " 'tipping',\n",
       " 'spun',\n",
       " 'collided',\n",
       " 'cult',\n",
       " 'officially',\n",
       " 'cancelled',\n",
       " 'Gotty',\n",
       " 'Hammers',\n",
       " 'detector',\n",
       " 'entered',\n",
       " 'Brennan',\n",
       " 'produce',\n",
       " 'signalled',\n",
       " 'replacements',\n",
       " 'list',\n",
       " 'prolong',\n",
       " 'heads',\n",
       " 'Guti',\n",
       " 'scores',\n",
       " 'force',\n",
       " 'Edelman',\n",
       " 'Libertadores',\n",
       " 'Lilley',\n",
       " 'inquest',\n",
       " 'fragmented',\n",
       " 'fancy',\n",
       " 'sort',\n",
       " 'Newey',\n",
       " 'Sven',\n",
       " 'Travis',\n",
       " 'precautionary',\n",
       " 'repeatedly',\n",
       " 'secret',\n",
       " 'Venus',\n",
       " 'separatist',\n",
       " 'construed',\n",
       " 'Feofanova',\n",
       " 'Mauresmo',\n",
       " 'grounded',\n",
       " 'Pires',\n",
       " 'Classy',\n",
       " 'national',\n",
       " 'hitting',\n",
       " 'assesses',\n",
       " 'scraps',\n",
       " 'exploit',\n",
       " 'Contepomi',\n",
       " 'studded',\n",
       " 'jockey',\n",
       " 'world',\n",
       " 'battled',\n",
       " 'Hungary',\n",
       " 'charged',\n",
       " 'rivalry',\n",
       " 'double',\n",
       " 'Ai',\n",
       " '185',\n",
       " 'ATP',\n",
       " 'Maybe',\n",
       " 'scraped',\n",
       " 'rob',\n",
       " 'Preston',\n",
       " 'meeting',\n",
       " 'interrupting',\n",
       " 'experimental',\n",
       " 'del',\n",
       " '39secs',\n",
       " 'ammunition',\n",
       " 'classic',\n",
       " 'collect',\n",
       " 'Islero',\n",
       " 'Mandula',\n",
       " 'unprovoked',\n",
       " 'chill',\n",
       " 'shortlived',\n",
       " 'invest',\n",
       " 'lined',\n",
       " 'controversial',\n",
       " 'tightening',\n",
       " 'thinks',\n",
       " 'Schubert',\n",
       " 'consultant',\n",
       " 'sessions',\n",
       " 'exhibition',\n",
       " 'Batistuta',\n",
       " '32',\n",
       " 'dispatched',\n",
       " 'awaits',\n",
       " 'Monica',\n",
       " '1200m',\n",
       " 'languishing',\n",
       " 'Independent',\n",
       " 'ambushed',\n",
       " 'MBEs',\n",
       " 'outline',\n",
       " 'Said',\n",
       " 'runs',\n",
       " 'Man',\n",
       " 'Styles',\n",
       " 'weighty',\n",
       " '1871',\n",
       " 'Marconnet',\n",
       " 'Americans',\n",
       " 'Hospices',\n",
       " 'racked',\n",
       " 'folk',\n",
       " 'Silvestre',\n",
       " 'Rigney',\n",
       " 'praised',\n",
       " 'survives',\n",
       " 'Malcolm',\n",
       " 'idolised',\n",
       " 'Students',\n",
       " 'Colchester',\n",
       " 'tests',\n",
       " 'guilty',\n",
       " 'minister',\n",
       " 'Arash',\n",
       " 'closer',\n",
       " 'handled',\n",
       " 'treat',\n",
       " 'Karmis',\n",
       " 'Playing',\n",
       " 'Ajax',\n",
       " 'Cotterills',\n",
       " 'Eton',\n",
       " 'governing',\n",
       " 'Beach',\n",
       " 'Shields',\n",
       " 'depending',\n",
       " 'Whether',\n",
       " 'Four',\n",
       " 'Webster',\n",
       " 'Philip',\n",
       " 'capped',\n",
       " 'Bromwich',\n",
       " 'months',\n",
       " 'refered',\n",
       " 'Intoppa',\n",
       " 'Hal',\n",
       " 'surprised',\n",
       " 'thousands',\n",
       " 'Hercus',\n",
       " 'Lamont',\n",
       " 'muscles',\n",
       " 'Balague',\n",
       " 'Laursen',\n",
       " 'grinding',\n",
       " 'Oliver',\n",
       " 'deceptively',\n",
       " 'gym',\n",
       " 'Rusedski',\n",
       " 'District',\n",
       " 'discipline',\n",
       " 'horror',\n",
       " 'pin',\n",
       " 'crave',\n",
       " 'Rovers',\n",
       " 'torn',\n",
       " 'Taylor',\n",
       " 'beforehand',\n",
       " 'header',\n",
       " 'rectify',\n",
       " 'Eighth',\n",
       " 'integrity',\n",
       " 'cruising',\n",
       " 'Poverty',\n",
       " 'Jolanda',\n",
       " 'sidelines',\n",
       " 'underestimating',\n",
       " 'Scots',\n",
       " 'Karina',\n",
       " 'common',\n",
       " 'Shevchenko',\n",
       " 'ABC',\n",
       " 'relish',\n",
       " 'Arbuckle',\n",
       " 'killed',\n",
       " 'stood',\n",
       " 'Gethin',\n",
       " 'Waalwijk',\n",
       " 'degrees',\n",
       " 'foes',\n",
       " 'despite',\n",
       " 'message',\n",
       " 'private',\n",
       " 'comprehensive',\n",
       " 'Fiszman',\n",
       " 'Stam',\n",
       " 'Uefa',\n",
       " 'Henson',\n",
       " 'featured',\n",
       " 'Matches',\n",
       " 'regional',\n",
       " 'courts',\n",
       " 'Te',\n",
       " 'disappointment',\n",
       " 'wobble',\n",
       " 'Espanyol',\n",
       " 'cautions',\n",
       " 'borrowing',\n",
       " 'Vaili',\n",
       " 'Joy',\n",
       " '1960s',\n",
       " 'Esperance',\n",
       " 'Gregan',\n",
       " 'players',\n",
       " 'salvaged',\n",
       " 'Neville',\n",
       " 'Appleford',\n",
       " 'ordinary',\n",
       " 'following',\n",
       " 'blasted',\n",
       " 'Bellamy',\n",
       " 'McConnell',\n",
       " 'duo',\n",
       " 'stutter',\n",
       " 'quaking',\n",
       " 'Carwyn',\n",
       " 'awesome',\n",
       " 'Palace',\n",
       " 'Inter',\n",
       " 'missiles',\n",
       " 'shots',\n",
       " 'Nicholls',\n",
       " 'Aware',\n",
       " 'reaches',\n",
       " 'copy',\n",
       " 'sweep',\n",
       " 'Den',\n",
       " 'equal',\n",
       " 'Oyedele',\n",
       " 'winless',\n",
       " 'pundit',\n",
       " 'dream',\n",
       " 'respecter',\n",
       " 'Einhoven',\n",
       " 'hello',\n",
       " 'brightly',\n",
       " 'stared',\n",
       " 'bow',\n",
       " 'sacked',\n",
       " 'circuit',\n",
       " 'berth',\n",
       " 'Tierney',\n",
       " 'Chronicle',\n",
       " 'permanent',\n",
       " '150',\n",
       " 'wise',\n",
       " 'Rutto',\n",
       " 'jump',\n",
       " 'knees',\n",
       " 'com',\n",
       " 'fit',\n",
       " 'scare',\n",
       " 'Nihat',\n",
       " 'Talal',\n",
       " 'launches',\n",
       " 'confidence',\n",
       " 'Hrbaty',\n",
       " 'Hartlepool',\n",
       " 'Cristiano',\n",
       " 'sporting',\n",
       " 'Cozza',\n",
       " 'Wild',\n",
       " 'suggests',\n",
       " 'Agent',\n",
       " 'supplying',\n",
       " 'undaunted',\n",
       " 'hared',\n",
       " 'contained',\n",
       " 'hooking',\n",
       " 'skipper',\n",
       " 'Makelele',\n",
       " 'inspection',\n",
       " 'Cobus',\n",
       " 'manner',\n",
       " 'cordon',\n",
       " 'Sapporo',\n",
       " 'sure',\n",
       " 'Zvonareva',\n",
       " 'Clay',\n",
       " 'dies',\n",
       " 'earmarked',\n",
       " 'feared',\n",
       " 'creaky',\n",
       " '94',\n",
       " 'treatment',\n",
       " 'posts',\n",
       " 'criticise',\n",
       " 'elements',\n",
       " 'looking',\n",
       " 'intention',\n",
       " 'scrappy',\n",
       " 'rotated',\n",
       " 'rehab',\n",
       " 'Vialli',\n",
       " 'abandoned',\n",
       " 'attractive',\n",
       " 'Chairman',\n",
       " 'hinted',\n",
       " 'Algemeen',\n",
       " 'disappointments',\n",
       " 'Afterwards',\n",
       " 'radius',\n",
       " 'Fawcett',\n",
       " 'state',\n",
       " 'clung',\n",
       " 'Zealand',\n",
       " 'Grewcock',\n",
       " 'competitions',\n",
       " 'Musampa',\n",
       " 'agonisingly',\n",
       " 'Shane',\n",
       " 'Agnes',\n",
       " 'unusual',\n",
       " 'approach',\n",
       " 'Philippe',\n",
       " 'innocuous',\n",
       " 'Michalak',\n",
       " 'overturn',\n",
       " 'require',\n",
       " 'Mullen',\n",
       " 'bottom',\n",
       " 'Federico',\n",
       " 'decisions',\n",
       " 'tension',\n",
       " 'Griffen',\n",
       " 'Enqvist',\n",
       " 'Sugiyama',\n",
       " 'waves',\n",
       " 'scooped',\n",
       " 'Santiago',\n",
       " 'registered',\n",
       " 'conducive',\n",
       " 'enforcement',\n",
       " 'humorous',\n",
       " 'Neeskens',\n",
       " 'Calder',\n",
       " 'Newcastle',\n",
       " ...}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sport_types = set(sport_tokens)\n",
    "print(\"types count : \" , len(sport_types))\n",
    "sport_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for techs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "types count :  13404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'stage',\n",
       " 'diverse',\n",
       " 'formulated',\n",
       " 'definitive',\n",
       " 'treated',\n",
       " 'stitching',\n",
       " 'foster',\n",
       " 'Exposition',\n",
       " 'Consortium',\n",
       " 'middle',\n",
       " 'survive',\n",
       " 'repair',\n",
       " 'Midlands',\n",
       " 'WAP',\n",
       " 'maintain',\n",
       " 'Beal',\n",
       " 'ET',\n",
       " 'oblige',\n",
       " '10',\n",
       " 'taste',\n",
       " 'Elspa',\n",
       " 'depress',\n",
       " 'Eva',\n",
       " 'rage',\n",
       " 'executed',\n",
       " 'refers',\n",
       " 'modernity',\n",
       " 'lifts',\n",
       " 'aspects',\n",
       " 'Users',\n",
       " 'liquid',\n",
       " 'seizing',\n",
       " 'appetite',\n",
       " 'sticker',\n",
       " 'closely',\n",
       " 'detected',\n",
       " 'existing',\n",
       " 'Bernard',\n",
       " 'offered',\n",
       " 'vibrant',\n",
       " 'meticulous',\n",
       " 'excuse',\n",
       " 'relentless',\n",
       " 'Satoru',\n",
       " 'packs',\n",
       " 'ferocious',\n",
       " 'haves',\n",
       " 'condition',\n",
       " 'Oxby',\n",
       " 'Plan',\n",
       " 'period',\n",
       " 'evidence',\n",
       " 'fashioned',\n",
       " 'Hewitt',\n",
       " 'brute',\n",
       " 'crystalline',\n",
       " 'Force',\n",
       " 'Bodinat',\n",
       " 'Wap',\n",
       " 'judgement',\n",
       " 'referred',\n",
       " 'license',\n",
       " 'colours',\n",
       " 'Night',\n",
       " 'coup',\n",
       " 'stringing',\n",
       " 'commissioner',\n",
       " 'Endor',\n",
       " 'Khomenei',\n",
       " 'credit',\n",
       " 'territory',\n",
       " 'AppleInsider',\n",
       " 'restrictive',\n",
       " 'Canada',\n",
       " 'GreenFairyDotcom',\n",
       " 'functions',\n",
       " 'simulated',\n",
       " 'muscling',\n",
       " 'VCRs',\n",
       " 'question',\n",
       " 'fraught',\n",
       " 'Strihavka',\n",
       " 'selects',\n",
       " 'healthcare',\n",
       " 'sanity',\n",
       " 'systems',\n",
       " 'reasonably',\n",
       " 'Tous',\n",
       " 'PhD',\n",
       " 'authentication',\n",
       " 'grade',\n",
       " 'Giselle',\n",
       " 'trailing',\n",
       " 'sucks',\n",
       " 'flat',\n",
       " 'prisoner',\n",
       " 'view',\n",
       " 'BST',\n",
       " 'debuts',\n",
       " 'multidimensional',\n",
       " 'DTI',\n",
       " 'registrars',\n",
       " 'Bangs',\n",
       " 'supported',\n",
       " 'Bringing',\n",
       " 'using',\n",
       " 'reduced',\n",
       " 'Spiderman',\n",
       " 'order',\n",
       " 'store',\n",
       " 'High',\n",
       " 'dotted',\n",
       " 'Bollywood',\n",
       " 'undeniable',\n",
       " 'sultry',\n",
       " 'Early',\n",
       " '178',\n",
       " 'persistence',\n",
       " 'envoy',\n",
       " 'guzzler',\n",
       " 'cartridges',\n",
       " 'millions',\n",
       " 'unrecycled',\n",
       " 'utilising',\n",
       " 'dismounting',\n",
       " 'Asteroid',\n",
       " 'Peruvian',\n",
       " 'tourists',\n",
       " 'microphone',\n",
       " 'monumental',\n",
       " 'JURI',\n",
       " 'slow',\n",
       " 'sneaks',\n",
       " 'fest',\n",
       " 'prosper',\n",
       " 'entering',\n",
       " 'Rio',\n",
       " 'composite',\n",
       " 'dealt',\n",
       " 'Souter',\n",
       " 'transfers',\n",
       " 'Souped',\n",
       " 'enthralling',\n",
       " 'revamped',\n",
       " 'declining',\n",
       " 'cops',\n",
       " 'proportion',\n",
       " 'Brightcove',\n",
       " 'viewing',\n",
       " 'Ellen',\n",
       " 'Kazaa',\n",
       " '2km',\n",
       " 'Tabloid',\n",
       " 'nuisance',\n",
       " 'Names',\n",
       " 'uploaded',\n",
       " 'Oh',\n",
       " 'military',\n",
       " 'Malgorzata',\n",
       " 'perpetrators',\n",
       " 'Orwellian',\n",
       " 'net',\n",
       " 'report',\n",
       " 'leaving',\n",
       " 'speak',\n",
       " 'Elliott',\n",
       " 'Need',\n",
       " 'rescue',\n",
       " 'Urgent',\n",
       " 'Trend',\n",
       " 'distort',\n",
       " 'minorities',\n",
       " 'masts',\n",
       " 'Surrey',\n",
       " 'subscribes',\n",
       " 'thrill',\n",
       " 'teamed',\n",
       " 'picked',\n",
       " 'perspective',\n",
       " 'intermittency',\n",
       " 'smudging',\n",
       " 'tastes',\n",
       " 'MIT',\n",
       " 'heated',\n",
       " 'Role',\n",
       " 'Arts',\n",
       " 'deserve',\n",
       " 'Musiwave',\n",
       " 'Rings',\n",
       " 'reluctant',\n",
       " 'levels',\n",
       " 'path',\n",
       " 'left',\n",
       " 'devoices',\n",
       " 'rankings',\n",
       " 'digits',\n",
       " 'Hilton',\n",
       " 'invasiveness',\n",
       " 'securely',\n",
       " 'impetus',\n",
       " 'Number',\n",
       " 'stock',\n",
       " 'business',\n",
       " 'Igels',\n",
       " 'Hi',\n",
       " 'Blogger',\n",
       " 'Populous',\n",
       " 'protagonists',\n",
       " 'Annoyingly',\n",
       " 'inspire',\n",
       " 'Hackarmy',\n",
       " 'Titanic',\n",
       " 'frozen',\n",
       " 'inboxes',\n",
       " 'set',\n",
       " 'voiced',\n",
       " 'Terrestrial',\n",
       " 'range',\n",
       " 'Valente',\n",
       " 'telco',\n",
       " 'mulls',\n",
       " 'Shin',\n",
       " 'rates',\n",
       " 'grips',\n",
       " 'standpoint',\n",
       " 'pulls',\n",
       " 'lab',\n",
       " 'void',\n",
       " 'Standing',\n",
       " 'exceeds',\n",
       " 'internationally',\n",
       " '13th',\n",
       " 'shark',\n",
       " 'showing',\n",
       " 'wrong',\n",
       " 'naively',\n",
       " 'creates',\n",
       " 'longest',\n",
       " 'Mitsubishi',\n",
       " 'inaugurated',\n",
       " 'refuses',\n",
       " 'tempted',\n",
       " 'Microprocessor',\n",
       " 'spelling',\n",
       " 'intended',\n",
       " 'barbary',\n",
       " 'Problems',\n",
       " 'Gage',\n",
       " 'Operation',\n",
       " 'CGA',\n",
       " 'Back',\n",
       " 'hotspots',\n",
       " 'adds',\n",
       " 'RSPCA',\n",
       " 'least',\n",
       " 'shut',\n",
       " 'tough',\n",
       " 'thwarts',\n",
       " 'forging',\n",
       " 'Standards',\n",
       " 'Park',\n",
       " 'school',\n",
       " 'publications',\n",
       " 'distribution',\n",
       " 'Stuart',\n",
       " 'individually',\n",
       " 'en',\n",
       " 'gadgetry',\n",
       " 'dying',\n",
       " 'meticulously',\n",
       " 'palm',\n",
       " 'impress',\n",
       " 'Organiser',\n",
       " 'interpreting',\n",
       " 'profiting',\n",
       " 'Vendor',\n",
       " 'cherish',\n",
       " 'MACROSPACE',\n",
       " 'daily',\n",
       " 'native',\n",
       " 'Lueders',\n",
       " 'whereabouts',\n",
       " 'hobby',\n",
       " 'Dublin',\n",
       " 'vastly',\n",
       " 'door',\n",
       " 'Gate',\n",
       " 'reassurance',\n",
       " 'partner',\n",
       " 'Borders',\n",
       " 'Einar',\n",
       " 'hiss',\n",
       " 'politicians',\n",
       " 'validate',\n",
       " 'readily',\n",
       " 'interchangeable',\n",
       " 'Bad',\n",
       " 'Rankin',\n",
       " 'motorcycle',\n",
       " 'iMP',\n",
       " 'job',\n",
       " 'uncouth',\n",
       " 'Hartog',\n",
       " 'TiVos',\n",
       " 'agency',\n",
       " 'Earlier',\n",
       " 'divulging',\n",
       " 'Schwarzenegger',\n",
       " 'planet',\n",
       " 'hots',\n",
       " 'struggles',\n",
       " 'cutting',\n",
       " 'espionage',\n",
       " 'legs',\n",
       " 'wake',\n",
       " 'country',\n",
       " '2940',\n",
       " 'catalogue',\n",
       " 'illicit',\n",
       " 'circulate',\n",
       " 'streamed',\n",
       " 'floats',\n",
       " 'Adapter',\n",
       " 'mongering',\n",
       " 'afflict',\n",
       " 'charismatic',\n",
       " 'unplug',\n",
       " 'originated',\n",
       " 'online',\n",
       " 'legally',\n",
       " 'horoscopes',\n",
       " 'tricky',\n",
       " 'March',\n",
       " 'suing',\n",
       " 'Voigt',\n",
       " 'Members',\n",
       " 'disengaged',\n",
       " 'pave',\n",
       " 'Jose',\n",
       " 'viable',\n",
       " 'PEDs',\n",
       " 'Jeremiah',\n",
       " 'answered',\n",
       " 'pleasing',\n",
       " 'agenda',\n",
       " 'dually',\n",
       " 'bland',\n",
       " 'alongside',\n",
       " 'Istanbul',\n",
       " 'journalism',\n",
       " 'ADSL',\n",
       " 'Wednesday',\n",
       " 'upping',\n",
       " 'pricey',\n",
       " 'Telco',\n",
       " 'adopters',\n",
       " 'vulnerabilities',\n",
       " 'Tool',\n",
       " 'wheels',\n",
       " 'convenient',\n",
       " '455',\n",
       " 'possibilities',\n",
       " 'cons',\n",
       " 'pots',\n",
       " 'malware',\n",
       " 'sender',\n",
       " 'Gadget',\n",
       " 'WMP',\n",
       " 'unaware',\n",
       " 'Theatre',\n",
       " 'Incredibles',\n",
       " 'surrounded',\n",
       " 'many',\n",
       " 'obtaining',\n",
       " 'gratuitously',\n",
       " 'factions',\n",
       " 'Curiously',\n",
       " 'Panlogic',\n",
       " 'differed',\n",
       " 'outfit',\n",
       " 'Dixons',\n",
       " 'Checkpoints',\n",
       " 'crisp',\n",
       " '5th',\n",
       " 'niches',\n",
       " 'warns',\n",
       " 'Betamax',\n",
       " 'crime',\n",
       " 'massive',\n",
       " 'Keeper',\n",
       " 'Jackson',\n",
       " 'Matrix',\n",
       " 'Goldstein',\n",
       " 'crank',\n",
       " 'Ken',\n",
       " 'innovating',\n",
       " 'operate',\n",
       " 'Voip',\n",
       " 'hobble',\n",
       " 'Compared',\n",
       " 'Designed',\n",
       " 'trackball',\n",
       " 'Finn',\n",
       " 'settings',\n",
       " 'Monsters',\n",
       " 'ported',\n",
       " 'superconducting',\n",
       " 'redirected',\n",
       " 'Prisoner',\n",
       " 'catch',\n",
       " 'particular',\n",
       " 'animals',\n",
       " 'obsession',\n",
       " '2mbps',\n",
       " '384',\n",
       " 'Gates',\n",
       " 'filmed',\n",
       " 'presently',\n",
       " 'thwart',\n",
       " 'inside',\n",
       " 'Benoit',\n",
       " 'penalised',\n",
       " 'products',\n",
       " 'tabloids',\n",
       " 'Mehdi',\n",
       " 'webpage',\n",
       " 'Publishers',\n",
       " 'volunteer',\n",
       " 'shrinking',\n",
       " 'ancient',\n",
       " 'Carr',\n",
       " 'Novastream',\n",
       " 'Sutherland',\n",
       " 'highs',\n",
       " 'yes',\n",
       " 'detects',\n",
       " 'gems',\n",
       " 'listed',\n",
       " 'minute',\n",
       " 'offer',\n",
       " 'thrown',\n",
       " 'capture',\n",
       " 'redder',\n",
       " 'disappear',\n",
       " 'Nineteen',\n",
       " 'unidentified',\n",
       " 'hood',\n",
       " 'dominance',\n",
       " 'expertise',\n",
       " 'Oftel',\n",
       " 'distant',\n",
       " 'brush',\n",
       " 'value',\n",
       " 'Credit',\n",
       " 'joked',\n",
       " 'doubling',\n",
       " 'Broadband',\n",
       " 'thoroughly',\n",
       " 'tightened',\n",
       " 'videos',\n",
       " 'Gammage',\n",
       " 'fulfil',\n",
       " 'mount',\n",
       " 'nice',\n",
       " 'VOD',\n",
       " 'fitness',\n",
       " 'draws',\n",
       " 'relayed',\n",
       " 'tunnel',\n",
       " 'pie',\n",
       " 'mercurial',\n",
       " 'Peter',\n",
       " 'minicabs',\n",
       " 'restlessness',\n",
       " 'Amaya',\n",
       " 'utility',\n",
       " 'poisoned',\n",
       " 'tea',\n",
       " 'chain',\n",
       " '2MB',\n",
       " 'updated',\n",
       " 'shuffle',\n",
       " 'Marcel',\n",
       " 'normal',\n",
       " 'together',\n",
       " 'drinks',\n",
       " 'resort',\n",
       " 'update',\n",
       " 'Soon',\n",
       " 'Kurt',\n",
       " 'expose',\n",
       " 'molecular',\n",
       " 'Fang',\n",
       " 'impressed',\n",
       " 'Allen',\n",
       " 'barriers',\n",
       " 'Nuclear',\n",
       " 'shading',\n",
       " 'Cafes',\n",
       " 'planning',\n",
       " 'interest',\n",
       " 'Haisheng',\n",
       " 'brokered',\n",
       " 'serendipity',\n",
       " 'obscure',\n",
       " 'guess',\n",
       " 'vulnerable',\n",
       " 'caught',\n",
       " 'parks',\n",
       " '500',\n",
       " 'export',\n",
       " 'Websites',\n",
       " 'limits',\n",
       " 'consoles',\n",
       " 'companies',\n",
       " 'mains',\n",
       " 'row',\n",
       " 'State',\n",
       " '36th',\n",
       " 'preventing',\n",
       " 'lived',\n",
       " 'pattern',\n",
       " 'silver',\n",
       " 'landscape',\n",
       " 'relatively',\n",
       " 'emerging',\n",
       " 'Sasser',\n",
       " 'surfaced',\n",
       " 'removable',\n",
       " 'creators',\n",
       " 'drive',\n",
       " 'catches',\n",
       " 'party',\n",
       " 'miniMIXA',\n",
       " 'Ensuring',\n",
       " 'intelligent',\n",
       " 'shaped',\n",
       " 'Enfish',\n",
       " 'summit',\n",
       " 'Searching',\n",
       " 'ROKR',\n",
       " 'Heine',\n",
       " 'extra',\n",
       " '40Mbps',\n",
       " 'Piper',\n",
       " 'ensure',\n",
       " 'tracking',\n",
       " 'convicted',\n",
       " 'Lumpur',\n",
       " 'travellers',\n",
       " 'personalise',\n",
       " 'publisher',\n",
       " 'Rahul',\n",
       " 'organised',\n",
       " 'drag',\n",
       " 'twins',\n",
       " 'Lyons',\n",
       " 'Radicati',\n",
       " '46m',\n",
       " 'Verisign',\n",
       " 'Adding',\n",
       " 'Thanks',\n",
       " '22',\n",
       " 'capabilities',\n",
       " 'Karen',\n",
       " 'cactus',\n",
       " 'solitary',\n",
       " 'identities',\n",
       " 'Swarm',\n",
       " 'production',\n",
       " 'swappers',\n",
       " 'innovator',\n",
       " 'Clara',\n",
       " 'Pervasive',\n",
       " 'Fishing',\n",
       " 'Wride',\n",
       " 'pm',\n",
       " 'categorisation',\n",
       " 'Jerry',\n",
       " 'pockets',\n",
       " 'interconnect',\n",
       " 'soaps',\n",
       " 'reflective',\n",
       " 'simulate',\n",
       " 'uphill',\n",
       " 'Respond',\n",
       " 'wheel',\n",
       " 'something',\n",
       " 'restructuing',\n",
       " 'stopped',\n",
       " 'bingo',\n",
       " 'supporting',\n",
       " 'XP2',\n",
       " '512',\n",
       " 'Industry',\n",
       " 'drawn',\n",
       " 'hope',\n",
       " 'share',\n",
       " 'Tracey',\n",
       " 'outflank',\n",
       " 'groundbreaking',\n",
       " 'journalist',\n",
       " 'nanotechnology',\n",
       " 'disturbing',\n",
       " 'harbouring',\n",
       " 'teachers',\n",
       " 'journalistic',\n",
       " 'crimes',\n",
       " 'portable',\n",
       " 'Calm',\n",
       " 'bugs',\n",
       " 'stand',\n",
       " 'evolve',\n",
       " '35km',\n",
       " 'groups',\n",
       " 'inspired',\n",
       " 'Stephenson',\n",
       " 'scrambler',\n",
       " 'Harris',\n",
       " 'pipeline',\n",
       " 'delivered',\n",
       " 'vigilantism',\n",
       " 'airport',\n",
       " 'allows',\n",
       " 'consult',\n",
       " 'Hanlon',\n",
       " 'Disney',\n",
       " 'produced',\n",
       " 'mutation',\n",
       " 'uncle',\n",
       " 'aspect',\n",
       " 'Coudenberg',\n",
       " 'runways',\n",
       " 'Hemin',\n",
       " 'initiatives',\n",
       " 'injunction',\n",
       " 'eyeballs',\n",
       " 'assumption',\n",
       " 'School',\n",
       " 'minor',\n",
       " 'announcing',\n",
       " 'administer',\n",
       " 'booked',\n",
       " 'bombard',\n",
       " 'Scotland',\n",
       " 'survived',\n",
       " 'enabled',\n",
       " 'backing',\n",
       " 'cultivated',\n",
       " 'Subaru',\n",
       " 'ice',\n",
       " 'solve',\n",
       " 'GPRS',\n",
       " 'official',\n",
       " '20GB',\n",
       " 'early',\n",
       " 'forgetting',\n",
       " 'Rory',\n",
       " 'advise',\n",
       " 'subsequent',\n",
       " '69',\n",
       " 'theoretically',\n",
       " 'satisfy',\n",
       " 'Todd',\n",
       " '36',\n",
       " 'soldiers',\n",
       " 'complaints',\n",
       " 'festive',\n",
       " 'Connectedness',\n",
       " '9bn',\n",
       " 'particularly',\n",
       " 'paves',\n",
       " 'adiction',\n",
       " 'follow',\n",
       " 'Griffiths',\n",
       " 'barrier',\n",
       " 'Banks',\n",
       " 'Employment',\n",
       " 'Radio',\n",
       " 'fields',\n",
       " 'related',\n",
       " 'assessment',\n",
       " 'semi',\n",
       " 'divides',\n",
       " 'yearly',\n",
       " 'viewpoint',\n",
       " 'AutoLink',\n",
       " '65bn',\n",
       " 'quantities',\n",
       " 'performance',\n",
       " 'Killzone',\n",
       " 'Wave',\n",
       " 'DC',\n",
       " 'overload',\n",
       " 'shuttle',\n",
       " 'unskilled',\n",
       " 'Khatami',\n",
       " 'Gawker',\n",
       " 'progress',\n",
       " 'peddle',\n",
       " 'museums',\n",
       " 'Yeob',\n",
       " 'combination',\n",
       " 'LLC',\n",
       " '90',\n",
       " 'Interactive',\n",
       " 'Services',\n",
       " 'relationship',\n",
       " 'root',\n",
       " 'beam',\n",
       " 'passive',\n",
       " 'mature',\n",
       " 'Rutkowski',\n",
       " 'Starcom',\n",
       " 'hype',\n",
       " 'buildyourown',\n",
       " 'rid',\n",
       " 'psychological',\n",
       " 'unhealthy',\n",
       " 'cylinder',\n",
       " 'unemployment',\n",
       " '512MB',\n",
       " 'Pete',\n",
       " 'spy',\n",
       " 'quite',\n",
       " 'Bankash',\n",
       " 'Wisconsin',\n",
       " 'complicated',\n",
       " 'Honours',\n",
       " 'omission',\n",
       " 'Larry',\n",
       " 'pressure',\n",
       " 'discovering',\n",
       " 'EBL',\n",
       " 'Towers',\n",
       " 'charity',\n",
       " 'ruling',\n",
       " 'century',\n",
       " 'fallen',\n",
       " 'titanium',\n",
       " 'Edinburgh',\n",
       " 'titbit',\n",
       " 'Personally',\n",
       " 'ago',\n",
       " 'galls',\n",
       " 'amid',\n",
       " 'Norway',\n",
       " 'Latinohiphopradio',\n",
       " 'rights',\n",
       " 'niggle',\n",
       " 'Less',\n",
       " 'joins',\n",
       " 'Flaherty',\n",
       " 'damn',\n",
       " 'loudmouth',\n",
       " 'chart',\n",
       " 'purely',\n",
       " 'children',\n",
       " 'extent',\n",
       " 'iPhoto',\n",
       " 'Pez',\n",
       " 'investors',\n",
       " 'addiction',\n",
       " 'grungy',\n",
       " 'se',\n",
       " 'DMB',\n",
       " 'footage',\n",
       " 'thirsts',\n",
       " 'authentic',\n",
       " 'founders',\n",
       " 'width',\n",
       " 'China',\n",
       " 'Africa',\n",
       " 'Crohas',\n",
       " 'cacophony',\n",
       " 'parked',\n",
       " 'Thursday',\n",
       " 'entirety',\n",
       " 'attracting',\n",
       " 'nevertheless',\n",
       " 'menacing',\n",
       " 'Fighting',\n",
       " 'superior',\n",
       " 'Advanced',\n",
       " 'employees',\n",
       " 'IDN',\n",
       " 'transparency',\n",
       " 'tag',\n",
       " 'licenses',\n",
       " 'inability',\n",
       " 'prosecution',\n",
       " 'finger',\n",
       " 'ons',\n",
       " 'cannon',\n",
       " 'ensuring',\n",
       " 'beckoned',\n",
       " 'secondary',\n",
       " 'summer',\n",
       " 'gothic',\n",
       " 'concerns',\n",
       " 'charming',\n",
       " 'fan',\n",
       " 'Freeview',\n",
       " 'snap',\n",
       " 'deco',\n",
       " 'None',\n",
       " 'Jeanne',\n",
       " 'taught',\n",
       " 'Racer',\n",
       " 'Dominic',\n",
       " 'tipping',\n",
       " 'Firefox',\n",
       " 'cult',\n",
       " 'officially',\n",
       " 'edutainment',\n",
       " 'eat',\n",
       " 'entered',\n",
       " 'noticeable',\n",
       " 'produce',\n",
       " 'signalled',\n",
       " 'trafficked',\n",
       " 'discourse',\n",
       " 'publish',\n",
       " 'list',\n",
       " 'incidentally',\n",
       " 'Zed',\n",
       " 'refunds',\n",
       " 'heads',\n",
       " 'force',\n",
       " 'scores',\n",
       " 'Republics',\n",
       " 'fragmented',\n",
       " 'fancy',\n",
       " 'resurrected',\n",
       " 'estimated',\n",
       " 'sort',\n",
       " 'Video',\n",
       " 'Sven',\n",
       " 'DeGroot',\n",
       " 'Travis',\n",
       " 'hotbed',\n",
       " 'repeatedly',\n",
       " 'secret',\n",
       " 'deathmatch',\n",
       " 'blurred',\n",
       " 'prices',\n",
       " 'lacks',\n",
       " 'grounded',\n",
       " 'national',\n",
       " 'hitting',\n",
       " 'Overture',\n",
       " 'sciences',\n",
       " 'bedrooms',\n",
       " 'emulators',\n",
       " 'reassure',\n",
       " 'exploit',\n",
       " 'aesthetic',\n",
       " 'conciliation',\n",
       " 'jockey',\n",
       " 'world',\n",
       " 'consists',\n",
       " 'Hungary',\n",
       " 'charged',\n",
       " 'advertise',\n",
       " 'pigs',\n",
       " 'splash',\n",
       " 'rivalry',\n",
       " 'double',\n",
       " 'HDTVs',\n",
       " 'Maybe',\n",
       " '25p',\n",
       " 'variants',\n",
       " 'feline',\n",
       " 'meeting',\n",
       " 'experimental',\n",
       " 'Telecommunications',\n",
       " 'classic',\n",
       " 'collect',\n",
       " 'Officer',\n",
       " 'informaton',\n",
       " 'pounds',\n",
       " 'furiously',\n",
       " 'flock',\n",
       " 'controversial',\n",
       " 'Exchange',\n",
       " 'tightening',\n",
       " 'thinks',\n",
       " 'consultant',\n",
       " 'sessions',\n",
       " 'MTV',\n",
       " 'exhibition',\n",
       " 'annoyances',\n",
       " 'fraction',\n",
       " 'programming',\n",
       " '32',\n",
       " 'archivists',\n",
       " 'rescuing',\n",
       " 'fingerprint',\n",
       " '8x10in',\n",
       " 'experimenting',\n",
       " 'sadder',\n",
       " 'infecting',\n",
       " 'cycles',\n",
       " '59th',\n",
       " 'Independent',\n",
       " 'outline',\n",
       " 'electroencephalogram',\n",
       " 'Said',\n",
       " 'runs',\n",
       " 'summed',\n",
       " 'Man',\n",
       " 'stream',\n",
       " 'Americans',\n",
       " 'adaptors',\n",
       " 'espanol',\n",
       " 'capitalise',\n",
       " 'sparse',\n",
       " 'racked',\n",
       " 'folk',\n",
       " 'object',\n",
       " 'commons',\n",
       " 'Operating',\n",
       " 'Implemented',\n",
       " 'Cory',\n",
       " 'praised',\n",
       " 'toxic',\n",
       " 'relevance',\n",
       " 'survives',\n",
       " 'Malcolm',\n",
       " 'Hume',\n",
       " 'ramifications',\n",
       " 'Behrmann',\n",
       " 'Students',\n",
       " 'beauty',\n",
       " 'WARS',\n",
       " 'guilty',\n",
       " 'minister',\n",
       " 'tests',\n",
       " 'naval',\n",
       " 'closer',\n",
       " 'Arash',\n",
       " 'evolving',\n",
       " 'treat',\n",
       " 'handled',\n",
       " 'comprising',\n",
       " 'Playing',\n",
       " 'iBand',\n",
       " 'Delivery',\n",
       " 'Eton',\n",
       " 'governing',\n",
       " 'Remote',\n",
       " 'depending',\n",
       " 'Though',\n",
       " 'Pied',\n",
       " 'Whether',\n",
       " 'Four',\n",
       " 'packet',\n",
       " 'Webster',\n",
       " 'Philip',\n",
       " 'Bloglines',\n",
       " 'capped',\n",
       " 'months',\n",
       " 'Design',\n",
       " 'Vetham',\n",
       " 'universe',\n",
       " 'Venturas',\n",
       " 'justifying',\n",
       " 'takings',\n",
       " 'thousands',\n",
       " 'surprised',\n",
       " 'purchases',\n",
       " 'muscles',\n",
       " 'Peer',\n",
       " 'MPIO',\n",
       " 'cafes',\n",
       " 'translating',\n",
       " 'contestants',\n",
       " 'grinding',\n",
       " 'Oliver',\n",
       " 'Bullfrog',\n",
       " 'patrol',\n",
       " 'gym',\n",
       " 'CEC',\n",
       " 'AMA',\n",
       " 'District',\n",
       " 'amend',\n",
       " 'thousand',\n",
       " 'marvel',\n",
       " 'paradise',\n",
       " 'imagery',\n",
       " 'discipline',\n",
       " 'Victims',\n",
       " 'pollution',\n",
       " 'RealArcade',\n",
       " 'Saumil',\n",
       " 'Public',\n",
       " 'horror',\n",
       " 'pin',\n",
       " 'plethora',\n",
       " 'crave',\n",
       " ...}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_types = set(tech_tokens)\n",
    "print(\"types count : \" , len(tech_types))\n",
    "tech_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 9-d:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of repeat football in sports = 93\n",
      "count of repeat football in Technology = 8\n",
      "count of repeat computer in sports = 0\n",
      "count of repeat computer in Technology = 299\n"
     ]
    }
   ],
   "source": [
    "for word in ['football','computer']:\n",
    "    for text_name , tokens_list in [(\"sports\",sport_tokens) , (\"Technology\" ,tech_tokens) ]:\n",
    "        print(f\"count of repeat {word} in {text_name} = {tokens_list.count(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 9-e:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_document = {}\n",
    "for word in sport_types.union(tech_types) :\n",
    "    term_document[word] = [sport_tokens.count(word),tech_tokens.count(word)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_matrix = pd.DataFrame(term_document.values() , index = term_document.keys() , columns=[\"sport\" ,\"tech\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sport</th>\n",
       "      <th>tech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hamm</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stage</th>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formulated</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treated</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foster</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assessed</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poles</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Koogle</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suited</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Often</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19378 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sport  tech\n",
       "Hamm            8     0\n",
       "stage          26    17\n",
       "formulated      0     1\n",
       "treated         6     3\n",
       "foster          1     3\n",
       "...           ...   ...\n",
       "assessed        1     1\n",
       "Poles           0     1\n",
       "Koogle          0     1\n",
       "suited          1     1\n",
       "Often           2     7\n",
       "\n",
       "[19378 rows x 2 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_doc_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part 9-f:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"football\",\"sport\",\"technology\",\"computer\",\"basketball\",\"laptop\",\"website\"]\n",
    "cos_similarities = numpy.zeros((7,7))\n",
    "for index1,word1 in enumerate(words):\n",
    "    for index2,word2 in enumerate(words):\n",
    "        cos_similarities[index1,index2]=1- cosine(term_doc_matrix.loc[word1].tolist() , term_doc_matrix.loc[word2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>football</th>\n",
       "      <th>sport</th>\n",
       "      <th>technology</th>\n",
       "      <th>computer</th>\n",
       "      <th>basketball</th>\n",
       "      <th>laptop</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>football</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988254</td>\n",
       "      <td>0.100045</td>\n",
       "      <td>0.085705</td>\n",
       "      <td>0.623970</td>\n",
       "      <td>0.085705</td>\n",
       "      <td>0.228332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>0.988254</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250923</td>\n",
       "      <td>0.236956</td>\n",
       "      <td>0.736062</td>\n",
       "      <td>0.236956</td>\n",
       "      <td>0.374434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>0.100045</td>\n",
       "      <td>0.250923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.839953</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.991542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>0.085705</td>\n",
       "      <td>0.236956</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basketball</th>\n",
       "      <td>0.623970</td>\n",
       "      <td>0.736062</td>\n",
       "      <td>0.839953</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>0.903278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laptop</th>\n",
       "      <td>0.085705</td>\n",
       "      <td>0.236956</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>website</th>\n",
       "      <td>0.228332</td>\n",
       "      <td>0.374434</td>\n",
       "      <td>0.991542</td>\n",
       "      <td>0.989570</td>\n",
       "      <td>0.903278</td>\n",
       "      <td>0.989570</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            football     sport  technology  computer  basketball    laptop  \\\n",
       "football    1.000000  0.988254    0.100045  0.085705    0.623970  0.085705   \n",
       "sport       0.988254  1.000000    0.250923  0.236956    0.736062  0.236956   \n",
       "technology  0.100045  0.250923    1.000000  0.999896    0.839953  0.999896   \n",
       "computer    0.085705  0.236956    0.999896  1.000000    0.832050  1.000000   \n",
       "basketball  0.623970  0.736062    0.839953  0.832050    1.000000  0.832050   \n",
       "laptop      0.085705  0.236956    0.999896  1.000000    0.832050  1.000000   \n",
       "website     0.228332  0.374434    0.991542  0.989570    0.903278  0.989570   \n",
       "\n",
       "             website  \n",
       "football    0.228332  \n",
       "sport       0.374434  \n",
       "technology  0.991542  \n",
       "computer    0.989570  \n",
       "basketball  0.903278  \n",
       "laptop      0.989570  \n",
       "website     1.000000  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cos_similarities , index=words , columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
